{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ContentUtil import ContentUtil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctl = ContentUtil()\n",
    "AI_data, Not_AI_data = ctl.load_with_label(\"datasets/AI/\", \"datasets/NOT/\")\n",
    "AI = np.array(AI_data)\n",
    "Not_AI = np.array(Not_AI_data)\n",
    "data = np.concatenate((AI, Not_AI), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amerucan computer gaming and artificil intelli...</td>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>American political scientist economist sociolo...</td>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Meta algorithmic technique to choose an algori...</td>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>science fiction trilogy by Peter F Hamilton T...</td>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Istituto italiano per l Intelligenza artif...</td>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data label\n",
       "0  Amerucan computer gaming and artificil intelli...    AI\n",
       "1  American political scientist economist sociolo...    AI\n",
       "2  Meta algorithmic technique to choose an algori...    AI\n",
       "3   science fiction trilogy by Peter F Hamilton T...    AI\n",
       "4  The Istituto italiano per l Intelligenza artif...    AI"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data,columns=[\"data\",\"label\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This article contains content that is written ...</td>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Research institute of the University of Southe...</td>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Visual arts in Sri Lanka refers to a variety o...</td>\n",
       "      <td>Art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hands on computing is a branch of human comput...</td>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>American legal case This article includes a li...</td>\n",
       "      <td>Art</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data label\n",
       "0  This article contains content that is written ...    AI\n",
       "1  Research institute of the University of Southe...    AI\n",
       "2  Visual arts in Sri Lanka refers to a variety o...   Art\n",
       "3  Hands on computing is a branch of human comput...    AI\n",
       "4  American legal case This article includes a li...   Art"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfshf = shuffle(df).reset_index(drop=True)\n",
    "dfshf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fdc74682128>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].value_counts().plot(kind='bar',title=\"Distribution of Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM, Activation, Dropout, Dense, Input,Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform text label into one-hot encoding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_d = df[\"label\"].to_numpy().reshape(-1,1)\n",
    "y_label = OneHotEncoder().fit(y_d).transform(y_d).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a column for text data length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"length\"] = df[\"data\"].apply(lambda x:len(x.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data and label to train set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"data\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test,Y_train, Y_test = train_test_split(X, y_label, test_size=0.2, random_state = 2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a tokenizer from Keras package and generate a dictionary for word and index. Use this dictionary to fill out the Glove embedding vector matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "words_to_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the glove vector from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glove_vector(glove_vec):\n",
    "    with open(glove_vec, 'r', encoding='UTF-8') as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            w_line = line.split()\n",
    "            curr_word = w_line[0]\n",
    "            word_to_vec_map[curr_word] = np.array(w_line[1:], dtype=np.float64)\n",
    "    return word_to_vec_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_vec_map = read_glove_vector('glove.6B.100d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.038194, -0.24487 ,  0.72812 , -0.39961 ,  0.083172,  0.043953,\n",
       "       -0.39141 ,  0.3344  , -0.57545 ,  0.087459,  0.28787 , -0.06731 ,\n",
       "        0.30906 , -0.26384 , -0.13231 , -0.20757 ,  0.33395 , -0.33848 ,\n",
       "       -0.31743 , -0.48336 ,  0.1464  , -0.37304 ,  0.34577 ,  0.052041,\n",
       "        0.44946 , -0.46971 ,  0.02628 , -0.54155 , -0.15518 , -0.14107 ,\n",
       "       -0.039722,  0.28277 ,  0.14393 ,  0.23464 , -0.31021 ,  0.086173,\n",
       "        0.20397 ,  0.52624 ,  0.17164 , -0.082378, -0.71787 , -0.41531 ,\n",
       "        0.20335 , -0.12763 ,  0.41367 ,  0.55187 ,  0.57908 , -0.33477 ,\n",
       "       -0.36559 , -0.54857 , -0.062892,  0.26584 ,  0.30205 ,  0.99775 ,\n",
       "       -0.80481 , -3.0243  ,  0.01254 , -0.36942 ,  2.2167  ,  0.72201 ,\n",
       "       -0.24978 ,  0.92136 ,  0.034514,  0.46745 ,  1.1079  , -0.19358 ,\n",
       "       -0.074575,  0.23353 , -0.052062, -0.22044 ,  0.057162, -0.15806 ,\n",
       "       -0.30798 , -0.41625 ,  0.37972 ,  0.15006 , -0.53212 , -0.2055  ,\n",
       "       -1.2526  ,  0.071624,  0.70565 ,  0.49744 , -0.42063 ,  0.26148 ,\n",
       "       -1.538   , -0.30223 , -0.073438, -0.28312 ,  0.37104 , -0.25217 ,\n",
       "        0.016215, -0.017099, -0.38984 ,  0.87424 , -0.72569 , -0.51058 ,\n",
       "       -0.52028 , -0.1459  ,  0.8278  ,  0.27062 ])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_vec_map[\"the\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define and initiate the embedding matrix with the shape (vocabulary_length, embedding length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voc_length is 149860 and embedding length is 100\n",
      "embedding matrix shape is (149860, 100)\n"
     ]
    }
   ],
   "source": [
    "vocab_len = len(words_to_index)\n",
    "embed_vector_len = word_to_vec_map['the'].shape[0]\n",
    "print(\"voc_length is {} and embedding length is {}\".format(vocab_len,embed_vector_len))\n",
    "emb_matrix = np.zeros((vocab_len, embed_vector_len))\n",
    "print(\"embedding matrix shape is {}\".format(emb_matrix.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, index in words_to_index.items():\n",
    "    embedding_vector = word_to_vec_map.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        emb_matrix[index-1, :] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model contains two Bi-directional LSTM layers together with two Dropout layers. Coming with three Dense layers. As for classifier layer, use sigmoid as activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(input_dim=vocab_len, output_dim=embed_vector_len, input_length=200, weights = [emb_matrix], trainable=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_indices = Input(shape=(None,))\n",
    "embeddings = embedding_layer(X_indices)\n",
    "x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(embeddings)\n",
    "x = Dropout(0.4)(x)\n",
    "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
    "x = Dropout(0.4)(x)\n",
    "# Add a classifier\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(3, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs=X_indices, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, None, 100)         14986000  \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, None, 128)         84480     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 15,196,243\n",
      "Trainable params: 210,243\n",
      "Non-trainable params: 14,986,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_indices = tokenizer.texts_to_sequences(X_train)\n",
    "X_train_indices = pad_sequences(X_train_indices, maxlen=200, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_indices = tokenizer.texts_to_sequences(X_test)\n",
    "X_test_indices = pad_sequences(X_test_indices, maxlen=200, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsp = keras.optimizers.RMSprop(learning_rate = 0.01)\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validating with test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3282 samples, validate on 821 samples\n",
      "Epoch 1/20\n",
      "3282/3282 [==============================] - 17s 5ms/sample - loss: 0.9332 - acc: 0.5771 - val_loss: 0.9236 - val_acc: 0.5688\n",
      "Epoch 2/20\n",
      "3282/3282 [==============================] - 16s 5ms/sample - loss: 0.8740 - acc: 0.5957 - val_loss: 0.8874 - val_acc: 0.6188\n",
      "Epoch 3/20\n",
      "3282/3282 [==============================] - 16s 5ms/sample - loss: 0.8448 - acc: 0.6106 - val_loss: 0.8148 - val_acc: 0.6407\n",
      "Epoch 4/20\n",
      "3282/3282 [==============================] - 15s 5ms/sample - loss: 0.7405 - acc: 0.6752 - val_loss: 0.7113 - val_acc: 0.6906\n",
      "Epoch 5/20\n",
      "3282/3282 [==============================] - 17s 5ms/sample - loss: 0.6594 - acc: 0.7246 - val_loss: 0.8476 - val_acc: 0.6151\n",
      "Epoch 6/20\n",
      "3282/3282 [==============================] - 16s 5ms/sample - loss: 0.6915 - acc: 0.7118 - val_loss: 0.6957 - val_acc: 0.7052\n",
      "Epoch 7/20\n",
      "3282/3282 [==============================] - 17s 5ms/sample - loss: 0.6034 - acc: 0.7562 - val_loss: 0.6330 - val_acc: 0.7247\n",
      "Epoch 8/20\n",
      "3282/3282 [==============================] - 15s 5ms/sample - loss: 0.5499 - acc: 0.7840 - val_loss: 0.6006 - val_acc: 0.7442\n",
      "Epoch 9/20\n",
      "3282/3282 [==============================] - 16s 5ms/sample - loss: 0.5184 - acc: 0.7962 - val_loss: 0.6021 - val_acc: 0.7503\n",
      "Epoch 10/20\n",
      "3282/3282 [==============================] - 15s 5ms/sample - loss: 0.5101 - acc: 0.8041 - val_loss: 0.7085 - val_acc: 0.7138\n",
      "Epoch 11/20\n",
      "3282/3282 [==============================] - 16s 5ms/sample - loss: 0.4606 - acc: 0.8254 - val_loss: 0.6340 - val_acc: 0.7649\n",
      "Epoch 12/20\n",
      "3282/3282 [==============================] - 15s 5ms/sample - loss: 0.4196 - acc: 0.8397 - val_loss: 0.6564 - val_acc: 0.7491\n",
      "Epoch 13/20\n",
      "3282/3282 [==============================] - 17s 5ms/sample - loss: 0.4062 - acc: 0.8483 - val_loss: 0.8087 - val_acc: 0.6699\n",
      "Epoch 14/20\n",
      "3282/3282 [==============================] - 17s 5ms/sample - loss: 0.4030 - acc: 0.8483 - val_loss: 0.6205 - val_acc: 0.7503\n",
      "Epoch 15/20\n",
      "3282/3282 [==============================] - 15s 5ms/sample - loss: 0.3363 - acc: 0.8769 - val_loss: 0.6213 - val_acc: 0.7759\n",
      "Epoch 16/20\n",
      "3282/3282 [==============================] - 16s 5ms/sample - loss: 0.3037 - acc: 0.8912 - val_loss: 0.5921 - val_acc: 0.7868\n",
      "Epoch 17/20\n",
      "3282/3282 [==============================] - 16s 5ms/sample - loss: 0.2446 - acc: 0.9174 - val_loss: 0.6648 - val_acc: 0.7686\n",
      "Epoch 18/20\n",
      "3282/3282 [==============================] - 16s 5ms/sample - loss: 0.2615 - acc: 0.9049 - val_loss: 0.6323 - val_acc: 0.7929\n",
      "Epoch 19/20\n",
      "3282/3282 [==============================] - 16s 5ms/sample - loss: 0.2009 - acc: 0.9314 - val_loss: 0.7646 - val_acc: 0.7978\n",
      "Epoch 20/20\n",
      "3282/3282 [==============================] - 15s 5ms/sample - loss: 0.2414 - acc: 0.9153 - val_loss: 0.6880 - val_acc: 0.7917\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_indices, Y_train, batch_size=128, epochs=20,validation_data=(X_test_indices, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3282 samples, validate on 821 samples\n",
      "Epoch 1/20\n",
      "3282/3282 [==============================] - 15s 4ms/sample - loss: 0.1864 - acc: 0.9342 - val_loss: 0.6700 - val_acc: 0.7881\n",
      "Epoch 2/20\n",
      "3282/3282 [==============================] - 15s 5ms/sample - loss: 0.1729 - acc: 0.9415 - val_loss: 0.7595 - val_acc: 0.7990\n",
      "Epoch 3/20\n",
      "3282/3282 [==============================] - 15s 5ms/sample - loss: 0.1403 - acc: 0.9525 - val_loss: 0.7784 - val_acc: 0.7881\n",
      "Epoch 4/20\n",
      "3282/3282 [==============================] - 15s 5ms/sample - loss: 0.1342 - acc: 0.9546 - val_loss: 0.7570 - val_acc: 0.8051\n",
      "Epoch 5/20\n",
      "3282/3282 [==============================] - 15s 5ms/sample - loss: 0.1232 - acc: 0.9592 - val_loss: 1.0434 - val_acc: 0.7333\n",
      "Epoch 6/20\n",
      "3282/3282 [==============================] - 15s 5ms/sample - loss: 0.1486 - acc: 0.9458 - val_loss: 0.8110 - val_acc: 0.7978\n",
      "Epoch 7/20\n",
      "3282/3282 [==============================] - 15s 5ms/sample - loss: 0.1044 - acc: 0.9662 - val_loss: 0.9006 - val_acc: 0.7856\n",
      "Epoch 8/20\n",
      "3282/3282 [==============================] - 15s 5ms/sample - loss: 0.0850 - acc: 0.9704 - val_loss: 0.8496 - val_acc: 0.7832\n",
      "Epoch 9/20\n",
      "3282/3282 [==============================] - 15s 5ms/sample - loss: 0.0849 - acc: 0.9711 - val_loss: 0.8564 - val_acc: 0.8039\n",
      "Epoch 10/20\n",
      "3282/3282 [==============================] - 15s 5ms/sample - loss: 0.0881 - acc: 0.9704 - val_loss: 0.9787 - val_acc: 0.7832\n",
      "Epoch 11/20\n",
      "3282/3282 [==============================] - 15s 5ms/sample - loss: 0.0946 - acc: 0.9647 - val_loss: 0.9335 - val_acc: 0.7978\n",
      "Epoch 12/20\n",
      "3282/3282 [==============================] - 15s 5ms/sample - loss: 0.0561 - acc: 0.9808 - val_loss: 1.0194 - val_acc: 0.7917\n",
      "Epoch 13/20\n",
      "3282/3282 [==============================] - 15s 5ms/sample - loss: 0.0685 - acc: 0.9771 - val_loss: 0.9296 - val_acc: 0.8185\n",
      "Epoch 14/20\n",
      "3282/3282 [==============================] - 15s 5ms/sample - loss: 0.0395 - acc: 0.9875 - val_loss: 1.0183 - val_acc: 0.7978\n",
      "Epoch 15/20\n",
      "3282/3282 [==============================] - 15s 5ms/sample - loss: 0.0869 - acc: 0.9711 - val_loss: 1.0069 - val_acc: 0.7942\n",
      "Epoch 16/20\n",
      "3282/3282 [==============================] - 15s 5ms/sample - loss: 0.0621 - acc: 0.9784 - val_loss: 1.0186 - val_acc: 0.7686\n",
      "Epoch 17/20\n",
      "3282/3282 [==============================] - 15s 5ms/sample - loss: 0.0832 - acc: 0.9671 - val_loss: 0.9255 - val_acc: 0.7576\n",
      "Epoch 18/20\n",
      "3282/3282 [==============================] - 15s 5ms/sample - loss: 0.0569 - acc: 0.9823 - val_loss: 0.9615 - val_acc: 0.8027\n",
      "Epoch 19/20\n",
      "3282/3282 [==============================] - 15s 5ms/sample - loss: 0.0259 - acc: 0.9918 - val_loss: 1.0067 - val_acc: 0.8100\n",
      "Epoch 20/20\n",
      "3282/3282 [==============================] - 15s 5ms/sample - loss: 0.0254 - acc: 0.9902 - val_loss: 1.0595 - val_acc: 0.7905\n"
     ]
    }
   ],
   "source": [
    "history2 = model.fit(X_train_indices, Y_train, batch_size=128, epochs=20,validation_data=(X_test_indices, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./result/Bi-LSTM_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
